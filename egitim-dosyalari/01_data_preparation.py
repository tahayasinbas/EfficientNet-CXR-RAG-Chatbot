"""
Veri HazÄ±rlama - Kaggle NIH Chest X-ray Dataset
TÃœM DATASET (112,120 gÃ¶rÃ¼ntÃ¼) + PATIENT-LEVEL SPLIT (Data leakage Ã¶nleme!)
Multi-label classification iÃ§in optimize edilmiÅŸ
FÄ°LTRELEME KALDIRILDI - Maximum performance iÃ§in tÃ¼m veri kullanÄ±lÄ±yor!
"""

import pandas as pd
from sklearn.model_selection import GroupShuffleSplit
from collections import Counter
import config
from pathlib import Path

print("="*70)
print(f"ğŸ“Š VERÄ° HAZIRLAMA BAÅLIYOR ({config.TOTAL_IMAGES:,} GÃ–RÃœNTÃœ)")
print("="*70)

# ==================== 1. ANA CSV'YÄ° OKU ====================
print("\n1ï¸âƒ£ Ana dataset yÃ¼kleniyor...")
df = pd.read_csv(config.CSV_FILE)
print(f"   âœ“ Toplam kayÄ±t: {len(df):,}")
print(f"   âœ“ Kolonlar: {list(df.columns)}")

# Patient ID extraction (Image Index format: 00000001_000.png â†’ Patient ID: 00000001)
df['Patient ID'] = df['Image Index'].str.split('_').str[0]
n_unique_patients = df['Patient ID'].nunique()
print(f"   âœ“ Benzersiz hasta sayÄ±sÄ±: {n_unique_patients:,}")

# ==================== 2. HASTALIK DAÄILIMI ANALÄ°ZÄ° ====================
print("\n2ï¸âƒ£ HastalÄ±k daÄŸÄ±lÄ±mÄ± analizi...")
all_findings = []
for finding in df['Finding Labels']:
    if finding == 'No Finding':
        all_findings.append('No Finding')
    else:
        all_findings.extend(finding.split('|'))

finding_counts = Counter(all_findings)
print("\n   Mevcut hastalÄ±k sayÄ±larÄ±:")
for disease in config.DISEASES:
    count = finding_counts.get(disease, 0)
    target = config.DISTRIBUTION.get(disease, 0)
    status = "âœ“" if count >= target else "âš "
    print(f"   {status} {disease:20s}: {count:6,} mevcut / {target:6,} hedef")

# ==================== 3. MULTI-LABEL STATÄ°STÄ°KLERÄ° ====================
print("\n3ï¸âƒ£ Multi-label analizi...")
multi_label_samples = 0
for finding in df['Finding Labels']:
    if finding != 'No Finding' and '|' in finding:
        multi_label_samples += 1

print(f"   Multi-label Ã¶rnekler: {multi_label_samples:,} / {len(df):,} "
      f"({multi_label_samples/len(df)*100:.1f}%)")

# ==================== 4. TÃœM VERÄ°YÄ° KULLAN (FÄ°LTRELEME YOK!) ====================
print("\n4ï¸âƒ£ TÃœM DATASET kullanÄ±lÄ±yor (FÄ°LTRELEME KALDIRILDI!)...")
print("   âœ… MAXIMUM PERFORMANCE: TÃ¼m 112,120 gÃ¶rÃ¼ntÃ¼ kullanÄ±lacak")
print("   âœ… TÃ¼m hastalÄ±k Ã¶rnekleri dahil (data loss yok!)")
print("   âœ… Multi-label iliÅŸkileri korunuyor")
print("   âœ… DoÄŸal hastalÄ±k daÄŸÄ±lÄ±mÄ± (class weights ile dengelenecek)")

# TÃ¼m veriyi kullan - FÄ°LTRELEME YOK!
df_selected_unique = df.copy()

print(f"\n   ğŸ“¦ Toplam gÃ¶rÃ¼ntÃ¼: {len(df_selected_unique):,}")
print(f"   ğŸ“¦ Benzersiz hasta: {df_selected_unique['Patient ID'].nunique():,}")

# HastalÄ±k daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶ster
print("\n   ğŸ“Š DoÄŸal hastalÄ±k daÄŸÄ±lÄ±mÄ± (tÃ¼m dataset):")
all_findings = []
for finding in df_selected_unique['Finding Labels']:
    if finding == 'No Finding':
        all_findings.append('No Finding')
    else:
        all_findings.extend(finding.split('|'))

finding_counts = Counter(all_findings)
for disease in config.DISEASES:
    count = finding_counts.get(disease, 0)
    percentage = (count / len(df_selected_unique)) * 100
    print(f"      {disease:20s}: {count:6,} ({percentage:5.1f}%)")

# ==================== 5. PATIENT-LEVEL SPLIT (Ã‡OK Ã–NEMLÄ°!) ====================
print("\n5ï¸âƒ£ PATIENT-LEVEL Split yapÄ±lÄ±yor...")
print("   âš ï¸  UYARI: AynÄ± hastanÄ±n gÃ¶rÃ¼ntÃ¼leri train/val/test'e karÄ±ÅŸmayacak!")

# Patient ID'lere gÃ¶re grup oluÅŸtur
patient_ids = df_selected_unique['Patient ID'].values

# Ä°lk split: Train vs (Val+Test)
# GroupShuffleSplit: Her hasta sadece bir sette olur
gss_train = GroupShuffleSplit(
    n_splits=1,
    test_size=(config.VAL_RATIO + config.TEST_RATIO),
    random_state=config.RANDOM_SEED
)

train_idx, temp_idx = next(gss_train.split(df_selected_unique, groups=patient_ids))

train_df = df_selected_unique.iloc[train_idx].reset_index(drop=True)
temp_df = df_selected_unique.iloc[temp_idx].reset_index(drop=True)

# Ä°kinci split: Val vs Test
temp_patient_ids = temp_df['Patient ID'].values
gss_val = GroupShuffleSplit(
    n_splits=1,
    test_size=config.TEST_RATIO / (config.VAL_RATIO + config.TEST_RATIO),
    random_state=config.RANDOM_SEED
)

val_idx, test_idx = next(gss_val.split(temp_df, groups=temp_patient_ids))

val_df = temp_df.iloc[val_idx].reset_index(drop=True)
test_df = temp_df.iloc[test_idx].reset_index(drop=True)

print(f"\n   âœ“ Train: {len(train_df):6,} gÃ¶rÃ¼ntÃ¼ ({len(train_df)/len(df_selected_unique)*100:.1f}%)")
print(f"   âœ“ Val:   {len(val_df):6,} gÃ¶rÃ¼ntÃ¼ ({len(val_df)/len(df_selected_unique)*100:.1f}%)")
print(f"   âœ“ Test:  {len(test_df):6,} gÃ¶rÃ¼ntÃ¼ ({len(test_df)/len(df_selected_unique)*100:.1f}%)")

# Patient overlap kontrolÃ¼ (OLMAMALI!)
train_patients = set(train_df['Patient ID'])
val_patients = set(val_df['Patient ID'])
test_patients = set(test_df['Patient ID'])

overlap_train_val = train_patients & val_patients
overlap_train_test = train_patients & test_patients
overlap_val_test = val_patients & test_patients

print(f"\n   ğŸ” Patient Overlap KontrolÃ¼:")
print(f"      Train-Val overlap: {len(overlap_train_val)} (0 olmalÄ±!)")
print(f"      Train-Test overlap: {len(overlap_train_test)} (0 olmalÄ±!)")
print(f"      Val-Test overlap: {len(overlap_val_test)} (0 olmalÄ±!)")

if len(overlap_train_val) == 0 and len(overlap_train_test) == 0 and len(overlap_val_test) == 0:
    print(f"      âœ… Patient-level split baÅŸarÄ±lÄ±! Data leakage yok.")
else:
    print(f"      âŒ UYARI: Patient overlap var! Split tekrar kontrol edin.")

# ==================== 6. HER SETTEDE HASTALIK DAÄILIMI ====================
print("\n6ï¸âƒ£ Her setteki hastalÄ±k daÄŸÄ±lÄ±mÄ±:")

for split_name, split_df in [('Train', train_df), ('Val', val_df), ('Test', test_df)]:
    findings = []
    for finding in split_df['Finding Labels']:
        if finding == 'No Finding':
            findings.append('No Finding')
        else:
            findings.extend(finding.split('|'))

    counts = Counter(findings)
    print(f"\n   {split_name} ({len(split_df):,} gÃ¶rÃ¼ntÃ¼, {split_df['Patient ID'].nunique()} hasta):")
    for disease in config.DISEASES:
        count = counts.get(disease, 0)
        percentage = (count / len(split_df)) * 100 if len(split_df) > 0 else 0
        print(f"     {disease:20s}: {count:4,} ({percentage:5.1f}%)")

# ==================== 7. CSV'LERÄ° KAYDET ====================
print("\n7ï¸âƒ£ CSV dosyalarÄ± kaydediliyor...")
output_dir = Path(config.OUTPUT_DIR)
output_dir.mkdir(exist_ok=True, parents=True)

csv_suffix = f"{config.TOTAL_IMAGES//1000}k"
train_df.to_csv(output_dir / f'train_{csv_suffix}.csv', index=False)
val_df.to_csv(output_dir / f'val_{csv_suffix}.csv', index=False)
test_df.to_csv(output_dir / f'test_{csv_suffix}.csv', index=False)

print(f"   âœ“ train_{csv_suffix}.csv kaydedildi ({len(train_df):,} satÄ±r)")
print(f"   âœ“ val_{csv_suffix}.csv kaydedildi ({len(val_df):,} satÄ±r)")
print(f"   âœ“ test_{csv_suffix}.csv kaydedildi ({len(test_df):,} satÄ±r)")

# ==================== 8. Ã–ZET Ä°STATÄ°STÄ°KLER ====================
print("\n" + "="*70)
print("ğŸ“Š VERÄ° HAZIRLAMA TAMAMLANDI!")
print("="*70)
print(f"\nâœ… Toplam seÃ§ilen: {len(df_selected_unique):,} benzersiz gÃ¶rÃ¼ntÃ¼")
print(f"   - Train: {len(train_df):,} ({len(train_df)/len(df_selected_unique)*100:.1f}%) - {train_df['Patient ID'].nunique()} hasta")
print(f"   - Val:   {len(val_df):,} ({len(val_df)/len(df_selected_unique)*100:.1f}%) - {val_df['Patient ID'].nunique()} hasta")
print(f"   - Test:  {len(test_df):,} ({len(test_df)/len(df_selected_unique)*100:.1f}%) - {test_df['Patient ID'].nunique()} hasta")

print(f"\nğŸ¯ Beklenen Performans:")
print(f"   - Hedef AUC: {config.EXPECTED_PERFORMANCE['target_auc']:.2f}")
print(f"   - Minimum AUC: {config.EXPECTED_PERFORMANCE['min_acceptable_auc']:.2f}")
print(f"   - EÄŸitim sÃ¼resi: ~{config.EXPECTED_PERFORMANCE['training_time_hours']:.1f} saat")
print(f"   - GPU memory: ~{config.EXPECTED_PERFORMANCE['gpu_memory_gb']:.0f} GB")

print("\nğŸ’¡ Ã–nemli Ä°yileÅŸtirmeler:")
print("   âœ… Patient-level split (data leakage Ã¶nlendi)")
print("   âœ… Multi-label iliÅŸkileri korundu")
print("   âœ… TÃœM 112,120 gÃ¶rÃ¼ntÃ¼ kullanÄ±ldÄ± (data loss YOK!)")
print("   âœ… TÃ¼m hastalÄ±klar tam temsil ediliyor")
print("   âœ… Kaggle dataset yapÄ±sÄ±na uyumlu")
print("   âœ… Filtreleme kaldÄ±rÄ±ldÄ± (basit + hatasÄ±z kod)")
print("   âœ… Class imbalance: CLASS_WEIGHTS + Focal Loss ile dengeleniyor")

print("\nğŸš€ Sonraki AdÄ±m: 04_train.py dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±n")
print("ğŸ¯ Beklenen AUC artÄ±ÅŸÄ±: 0.77 â†’ 0.85-0.87+ âœ…")
print("="*70)
